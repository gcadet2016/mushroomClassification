{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5fe66c",
   "metadata": {},
   "source": [
    "# E02 - Entrainement modèle DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd946c31",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade33372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99e85b",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "%load_ext tensorboard\n",
    "log_dir = '/'\n",
    "tensorboard = callbacks.TensorBoard(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2916868",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01954b62",
   "metadata": {},
   "source": [
    " Le surapprentissage est un cauchemar pour les praticiens du Machine Learning. Une façon de l’éviter consiste à interrompre le processus prématurément. La fonction EarlyStopping a diverses métriques / arguments que vous pouvez modifier pour définir le moment où le processus d'entraînement doit s'arrêter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', \n",
    "                               min_delta = 0.01,\n",
    "                               patience = 5,\n",
    "                               verbose = 1,\n",
    "                               mode = 'auto',\n",
    "                               restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0f4c7",
   "metadata": {},
   "source": [
    "- **monitor** Métrique à surveiller pour déclencher l'arrêt anticipé, par exemple, 'val_loss' pour la perte sur l'ensemble de validation ou 'val_accuracy' pour l'exactitude sur l'ensemble de validation.\n",
    "- **min_delta** Différence minimale considérée comme une amélioration de la métrique surveillée. Une valeur par défaut de 0 signifie que toute amélioration sera considérée comme significative.\n",
    "- **patience** Le nombre d'époques sans amélioration de la métrique surveillée avant que l'entraînement ne soit arrêté.\n",
    "    - Par exemple, si patience=3, l'entraînement sera arrêté si la métrique ne s'améliore pas pendant trois époques consécutives.\n",
    "- **verbose** Niveau de verbosité pour les messages pendant l'entraînement. Un entier (0, 1 ou 2) ou un booléen (True ou False).\n",
    "- **mode** Le mode de la métrique à surveiller. Il peut prendre les valeurs 'auto', 'min' ou 'max'. Dans le cas de 'auto', il sera automatiquement déduit en fonction de la métrique surveillée.\n",
    "- **baseline** La valeur de référence de la métrique à partir de laquelle les améliorations seront calculées. Si la métrique surveillée n'améliore pas la valeur de référence, l'entraînement sera arrêté.\n",
    "- **restore_best_weights** Un booléen indiquant si les meilleurs poids du modèle doivent être restaurés après l'arrêt de l'entraînement. \n",
    "    - Si True, les poids du modèle à la fin de la meilleure époque seront restaurés.\n",
    "    - Si False, les poids du modèle à la fin de la dernière époque seront utilisés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195bc8d",
   "metadata": {},
   "source": [
    "### ReduceLearningRate (ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522d0e0",
   "metadata": {},
   "source": [
    "Permet de réduire le taux d'apprentissage (learning rate) du modèle lorsque certaines conditions sont remplies, ce qui peut aider à améliorer la convergence du modèle et à éviter de rester bloqué dans des minimas locaux lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1335083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "earlystop = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                        min_delta = 0.01,\n",
    "                        patience = 3,\n",
    "                        factor = 0.2, \n",
    "                        cooldown = 3,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e463a7a",
   "metadata": {},
   "source": [
    "- **monitor** Métrique à surveiller pour déclencher la réduction du taux d'apprentissage, par exemple, 'val_loss' pour la perte sur l'ensemble de validation ou 'val_accuracy' pour l'exactitude sur l'ensemble de validation.\n",
    "- **factor** Facteur de réduction du taux d'apprentissage. Après chaque déclenchement, le taux d'apprentissage sera multiplié par ce facteur.\n",
    "    - Par exemple, si factor=0.1, le taux d'apprentissage sera réduit à 10% de sa valeur actuelle.\n",
    "- **patience** Nombre d'époques sans amélioration de la métrique surveillée avant de réduire le taux d'apprentissage.\n",
    "    - Par exemple, si patience=3, le taux d'apprentissage sera réduit si la métrique ne s'améliore pas pendant trois époques consécutives.\n",
    "- **verbose** Niveau de verbosité pour les messages pendant l'entraînement. Un entier (0, 1 ou 2) ou un booléen (True ou False).\n",
    "- **mode** Mode de la métrique à surveiller. Il peut prendre les valeurs 'auto', 'min' ou 'max'. Dans le cas de 'auto', il sera automatiquement déduit en fonction de la métrique surveillée.\n",
    "- **min_delta** Différence minimale considérée comme une amélioration de la métrique surveillée. Une valeur par défaut de 0 signifie que toute amélioration sera considérée comme significative.\n",
    "- **cooldown** Nombre d'époques supplémentaires à attendre après une réduction du taux d'apprentissage avant de reprendre une surveillance normale. Cela permet d'éviter de réduire le taux d'apprentissage de manière trop fréquente.\n",
    "- **min_lr** Valeur plancher pour le taux d'apprentissage. Le taux d'apprentissage ne sera pas réduit en dessous de cette valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ad2dc",
   "metadata": {},
   "source": [
    "### ModelCheckPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32418dfd",
   "metadata": {},
   "source": [
    "Permet de sauvegarder les poids du modèle à certains moments pendant l'entraînement. Cela permet de conserver les poids du modèle ayant les meilleures performances sur l'ensemble de validation ou à des étapes spécifiques de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath='best_model', monitor='val_accuracy', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd30747",
   "metadata": {},
   "source": [
    "- **filepath** Chemin du fichier où les poids du modèle seront sauvegardés. Vous pouvez utiliser des motifs de noms de fichiers pour inclure des informations variables telles que le numéro de l'époque dans le nom du fichier.\n",
    "- **monitor** Métrique à surveiller pour déterminer les meilleurs poids du modèle, par exemple, 'val_loss' pour la perte sur l'ensemble de validation ou 'val_accuracy' pour l'exactitude sur l'ensemble de validation.\n",
    "- **save_best_only** Booléen indiquant si seuls les meilleurs poids du modèle doivent être sauvegardés. Si True, seuls les poids qui améliorent la métrique surveillée seront sauvegardés.\n",
    "- **save_weights_only** Booléen indiquant si seuls les poids du modèle doivent être sauvegardés (True) ou s'il faut sauvegarder tout le modèle, y compris l'architecture (False).\n",
    "- **mode** Mode de la métrique à surveiller. Il peut prendre les valeurs 'auto', 'min' ou 'max'. Dans le cas de 'auto', il sera automatiquement déduit en fonction de la métrique surveillée.\n",
    "- **verbose** Niveau de verbosité pour les messages pendant l'entraînement. Un entier (0, 1 ou 2) ou un booléen (True ou False).\n",
    "- **save_freq** Fréquence à laquelle les poids du modèle seront sauvegardés. Il peut être un entier (nombre d'époques entre chaque sauvegarde), ou une chaîne de caractères 'epoch' (pour sauvegarder à la fin de chaque époque) ou 'batch' (pour sauvegarder à la fin de chaque lot/batch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d982e",
   "metadata": {},
   "source": [
    "### LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588fdce2",
   "metadata": {},
   "source": [
    "Permet de modifier le taux d'apprentissage (learning rate) du modèle à des étapes spécifiques de l'entraînement en fonction d'une fonction définie par l'utilisateur. Cela permet d'ajuster dynamiquement le taux d'apprentissage pendant l'entraînement pour améliorer la convergence du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c14a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# Définition de la fonction pour ajuster le taux d'apprentissage\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Fonction pour ajuster le taux d'apprentissage en fonction de l'époque.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.1\n",
    "    if epoch > 50:\n",
    "        learning_rate = 0.01\n",
    "    if epoch > 100:\n",
    "        learning_rate = 0.001\n",
    "    return learning_rate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0e7da",
   "metadata": {},
   "source": [
    "- **schedule** La fonction qui définit le taux d'apprentissage en fonction du numéro de l'époque. Cette fonction prend comme entrée l'époque actuelle (un entier) et renvoie le taux d'apprentissage souhaité (un nombre).\n",
    "- **verbose** Niveau de verbosité pour les messages pendant l'entraînement. Un entier (0, 1 ou 2) ou un booléen (True ou False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89838b98",
   "metadata": {},
   "source": [
    "### Timing Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f6648",
   "metadata": {},
   "source": [
    "Mesure le temps écoulé entre les epochs et début et de fin de calllback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2de64",
   "metadata": {},
   "source": [
    "### TerminateOnNan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195108f3",
   "metadata": {},
   "source": [
    "Permet de stopper l'entraînement quand la fonction de perte a divergé (de valeur NaN). Ce callback peut être utile pour éviter de continuer à entraîner le modèle s'il a divergé ou d'arrêter le calcul en cas de données non conformes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "TON = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40384522",
   "metadata": {},
   "source": [
    "### Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Documentation : https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de custom :\n",
    "class CustomCallBack(Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print('Pour le batch {}, l\\'erreur de train est {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('La perte de validation pour l\\'epoch {} est {:7.2f} et la métrique est {:7.2f}.'.format(epoch, logs['val_loss'], logs['val_mean_absolute_error']))\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        print('Validation finie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e9683",
   "metadata": {},
   "source": [
    "## Fit classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8748816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tailles des échantillons\n",
    "nb_img_train = train_generator.samples\n",
    "nb_img_test = test_generator.samples\n",
    "\n",
    "model_history = model.fit(generator = train_dataset,\n",
    "                          validation_data = test_dataset,\n",
    "                          epochs = 20,\n",
    "                          steps_per_epoch = nb_img_train // batch_size, \n",
    "                          validation_steps = nb_img_test // batch_size,\n",
    "                          callbacks = [tensorboard],\n",
    "                          verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2c8f6",
   "metadata": {},
   "source": [
    "- **generator** Les données d'entraînement. Cela peut être un tableau NumPy ou un générateur de données.\n",
    "- **validation_data** Les données de validation utilisées pour évaluer le modèle à la fin de chaque époque. Cela peut être un tuple contenant les données de validation et les étiquettes associées, ou un générateur de données.\n",
    "- **epochs**  Spécifie le nombre d'itérations d'entraînement que le modèle effectuera sur l'ensemble des données.\n",
    "- **steps_per_epoch** Le nombre d'itérations (pas) à effectuer par époque d'entraînement. Il correspond au nombre total d'échantillons d'entraînement divisé par la taille du batch.\n",
    "- **validation_split**  Spécifie la proportion d'exemples à utiliser pour la validation.\n",
    "    - Lors de l'entraînement, le modèle utilise une partie des données (1 - validation_split) pour l'apprentissage, et le reste (validation_split) pour la validation, afin d'évaluer les performances du modèle sur un ensemble de données distinct et de détecter le surapprentissage.   \n",
    "- **batch_size** Détermine la taille de chaque lot (ou batch) de données utilisé pour une mise à jour des poids du modèle.       \n",
    "- **validation_steps** Le nombre d'itérations (pas) à effectuer par époque de validation. Il correspond au nombre total d'échantillons de validation divisé par la taille du batch. Dans cet exemple, nb_img_test // batch_size est utilisé pour spécifier le nombre de pas par époque de validation.\n",
    "- **callbacks**  Liste de callbacks à utiliser pendant l'entraînement.\n",
    "- **shuffle** Booléen indiquant si les données doivent être mélangées avant chaque époque. Par défaut, il est défini à True.\n",
    "- **class_weight** Dictionnaire indiquant comment pondérer les classes. Utile pour équilibrer les classes déséquilibrées dans un problème de classification.\n",
    "- **sample_weight** Tableau de poids associé à chaque échantillon. Utile pour attribuer des poids différents à certains échantillons lors de l'entraînement.\n",
    "- **initial_epoch** Epoque à partir de laquelle commencer l'entraînement. Cela peut être utile si vous souhaitez reprendre l'entraînement d'un modèle à partir d'une époque spécifique\n",
    "- **verbose**  Niveau de verbosité pour les messages pendant l'entraînement. Un entier (0, 1 ou 2) ou un booléen (True ou False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f86df",
   "metadata": {},
   "source": [
    "## Fit personnalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74623c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entrainnement\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "def train_op(model,inputs,targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs, training = True)\n",
    "        loss_value = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(targets, y_pred))\n",
    "        \n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    return loss_value.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainnement\n",
    "grads = []\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    for X_t, y_t in dataset:\n",
    "        train_op(model, X_t, y_t)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_test, model(X_test.reshape([-1,28,28,1])))).numpy()\n",
    "    print('epoch', i, 'loss :', loss)\n",
    "    grads.append(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
