{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle basé sur un échentillon des 10 espèces les plus représentées.\n",
    "# L'objectif est d'observer la qualité d'entrainement d'un modèle sur un echantillon réduit.\n",
    "# La vitesse d'entrainnement du modèle permet d'ajuster facilement les paramètres et les callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10ca74",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2433fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "#import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70801108",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9c95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df(chemin_images, chemin_csv, pourcentage_echantillon):\n",
    "    '''Importe le fichier csv et construit 4 df :\n",
    "        - df reprenant l'ensemble des données\n",
    "        - df_ech est un echantillon de df\n",
    "        - top10 ne reprend que les 10 labels les plus vus dans df\n",
    "        - top10_ech est un echantillon de top10\n",
    "        '''\n",
    "\n",
    "    # import du df\n",
    "    df = pd.read_csv(chemin_csv, low_memory=False)\n",
    "    df['image_url'] = df['image_url'].str.replace('.../images/', chemin_images)\n",
    "    print(f\"Nombre d'images chargées pour df: {df.shape[0]}\")\n",
    "    print(f\"Nb especes dans df: {df['label'].nunique()}\")\n",
    "\n",
    "\n",
    "    # Contruction de l'echantillon\n",
    "    L = len(df)\n",
    "    L_ech = int(pourcentage_echantillon * L)\n",
    "    df_ech = df.sample(n=L_ech, random_state=10)\n",
    "    df_ech.reset_index(inplace=True, drop=True)\n",
    "    print(f\"Nombre d'images chargées pour df_ech: {df_ech.shape[0]}\")\n",
    "    print(f\"Nb especes dans df_ech: {df_ech['label'].nunique()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df, df_ech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a199e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def augment_img(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = (img - tf.math.reduce_min(img)) / (tf.math.reduce_max(img) - tf.math.reduce_min(img))\n",
    "    #img = tf.image.random_rotation(img)\n",
    "    #img = tf.image.random_crop(img)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f21c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(image_path, labels, batch_size):\n",
    "    image_path = image_path.tolist()  # Convertir les chemins d'images en liste\n",
    "    labels = labels.tolist()  # Convertir les labels en liste\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, labels))\n",
    "    dataset = dataset.map(augment_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_path))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e45307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def controle_presence_fichiers(df, chemin_images):\n",
    "\n",
    "\n",
    "    image_directory = chemin_images\n",
    "    missing_files = []\n",
    "\n",
    "# Parcourir chaque ligne du DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = os.path.join(image_directory, row['image_lien'])\n",
    "    \n",
    "        if not os.path.exists(image_path):\n",
    "            missing_files.append(image_path)\n",
    "\n",
    "    # Afficher les fichiers non trouvés\n",
    "    if missing_files:\n",
    "        print(\"\\nFichiers non trouvés :\")\n",
    "        for file_path in missing_files:\n",
    "            print(file_path)\n",
    "    else:\n",
    "        print(\"\\nTous les fichiers sont présents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09d4f9",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0bdb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "%load_ext tensorboard\n",
    "log_dir = '/'\n",
    "tensorboard = callbacks.TensorBoard(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f239b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', \n",
    "                               min_delta = 0.01,\n",
    "                               patience = 3,\n",
    "                               verbose = 1,\n",
    "                               mode = 'auto',\n",
    "                               restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e47c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "earlystop = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                        min_delta = 0.01,\n",
    "                        patience = 3,\n",
    "                        factor = 0.15, \n",
    "                        cooldown = 3,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016cc5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath='../model/model_complet', monitor='val_accuracy', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eca22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# Définition de la fonction pour ajuster le taux d'apprentissage\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Fonction pour ajuster le taux d'apprentissage en fonction de l'époque.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.1\n",
    "    if epoch > 15:\n",
    "        learning_rate = 0.01\n",
    "    if epoch > 40:\n",
    "        learning_rate = 0.001\n",
    "    return learning_rate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e8637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b133929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "TON = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec66ae9",
   "metadata": {},
   "source": [
    "# Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911cb8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images chargées pour df: 64372\n",
      "Nb especes dans df: 10\n",
      "Nombre d'images chargées pour df_ech: 6437\n",
      "Nb especes dans df_ech: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_9612\\1086476059.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['image_url'] = df['image_url'].str.replace('.../images/', chemin_images)\n"
     ]
    }
   ],
   "source": [
    "chemin_images = '../../images/'\n",
    "chemin_csv = '../data/top10.csv'\n",
    "pourcentage_echantillon = 0.1 # Si 0.1 : 10% du contenu\n",
    "\n",
    "\n",
    "df, df_ech = import_df(chemin_images, chemin_csv, pourcentage_echantillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb086179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image_lien</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agaricales</td>\n",
       "      <td>486562.jpg</td>\n",
       "      <td>../../images/486562.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agaricales</td>\n",
       "      <td>509189.jpg</td>\n",
       "      <td>../../images/509189.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agaricales</td>\n",
       "      <td>486561.jpg</td>\n",
       "      <td>../../images/486561.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agaricales</td>\n",
       "      <td>231418.jpg</td>\n",
       "      <td>../../images/231418.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agaricales</td>\n",
       "      <td>508881.jpg</td>\n",
       "      <td>../../images/508881.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  image_lien                image_url\n",
       "0  Agaricales  486562.jpg  ../../images/486562.jpg\n",
       "1  Agaricales  509189.jpg  ../../images/509189.jpg\n",
       "2  Agaricales  486561.jpg  ../../images/486561.jpg\n",
       "3  Agaricales  231418.jpg  ../../images/231418.jpg\n",
       "4  Agaricales  508881.jpg  ../../images/508881.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc35b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tous les fichiers sont présents.\n"
     ]
    }
   ],
   "source": [
    "controle_presence_fichiers(df, chemin_images)\n",
    "df.drop('image_lien', axis=1, inplace=True)\n",
    "df_ech.drop('image_lien', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6139e",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b131d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 1000)              7200312   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                64064     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7266786 (27.72 MB)\n",
      "Trainable params: 66474 (259.66 KB)\n",
      "Non-trainable params: 7200312 (27.47 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "efficientnet_url = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/classification/2'\n",
    "efficientNet = hub.KerasLayer(efficientnet_url, trainable=False)\n",
    "\n",
    "\n",
    "# Créer le modèle EfficientNet sans les couches de classification\n",
    "input_layer = layers.Input(shape=(224, 224, 3))\n",
    "x = efficientNet(input_layer)\n",
    "efficientNet = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "# Créer le modèle CNN\n",
    "model = models.Sequential()\n",
    "model.add(efficientNet)\n",
    "\n",
    "# Couche entièrement connectée\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # 10 classes de sortie\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Afficher un résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa41ff",
   "metadata": {},
   "source": [
    "## Jeux train, test & val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5914f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('label', axis=1)\n",
    "target = df['label']\n",
    "\n",
    "s = LabelEncoder()\n",
    "target = s.fit_transform(target)\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, target, test_size=0.25, random_state=10)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0642c4c",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1652c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_train= create_tf_dataset(X_train.image_url, y_train, batch_size)\n",
    "ds_test = create_tf_dataset(X_test.image_url, y_test, batch_size)\n",
    "ds_val = create_tf_dataset(X_val.image_url, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bab9f7",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dabef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch = X_train.shape[0] // batch_size\n",
    "\n",
    "\n",
    "history_ech = model.fit(ds_train,\n",
    "                        validation_data = ds_val,\n",
    "                        epochs=30,\n",
    "                        callbacks = [tensorboard, early_stopping, earlystop, checkpoint, lr_scheduler, time_callback, TON],\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d73eea",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1676f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "test_loss_ech, test_accuracy_ech = model.evaluate(ds_test_ech)\n",
    "print(\"Test accuracy:\", test_accuracy_ech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b888b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_ech.history['accuracy'], label='accuracy')\n",
    "plt.plot(history_ech.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6405b",
   "metadata": {},
   "source": [
    "## Interprétabilité (Grad Cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a046678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (224, 224)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "# Chemin local vers image\n",
    "img_path = keras.utils.get_file('../../images/28.jpg')\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 224x224\n",
    "    img = keras.utils.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (224, 292249, 3)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 224, 224, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eff691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "# Make model\n",
    "grad = model_builder(weights=\"imagenet\")\n",
    "\n",
    "# Remove last layer's softmax\n",
    "grad.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = grad.predict(img_array)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7410d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4b9b9",
   "metadata": {},
   "source": [
    "## Sauvegarde modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/modele_complet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
